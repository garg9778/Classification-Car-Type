{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac619629",
   "metadata": {},
   "source": [
    "# Car Evaluations dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4287c96b",
   "metadata": {},
   "source": [
    "We now look at the car evaluations dataset. We start by downloading the same, and then loading the same into a pandas dataframe. We then convert it into a numpy array, same as done with the wdbc dataset. \n",
    "\n",
    "There are 6 attributes in the dataset:\n",
    "\n",
    "1. buying       v-high, high, med, low\n",
    "2. maint        v-high, high, med, low\n",
    "3. doors        2, 3, 4, 5-more\n",
    "4. persons      2, 4, more\n",
    "5. lug_boot     small, med, big\n",
    "6. safety       low, med, high"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36733fd9",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd49f1",
   "metadata": {},
   "source": [
    "We start by importing all necessary libraries for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36ceb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all necessary libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, tree, linear_model, naive_bayes\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets, preprocessing, metrics\n",
    "from sklearn.metrics import f1_score, make_scorer, accuracy_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import scikitplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866fbd8",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db8990d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load entire data in one numpy array\n",
    "car_raw = pd.read_csv('car.data', delimiter=\",\", names=[\n",
    "        'buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class'])\n",
    "car_raw = car_raw.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d8795",
   "metadata": {},
   "source": [
    "## Training Testing Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9729f07",
   "metadata": {},
   "source": [
    "We split this data into training and testing with 80:20 ratio to keep aside some data for our final model evaluation. We do our model selection and hyperparameter search on the training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce00d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample count of training:  1209\n",
      "Sample count of testing:  519\n"
     ]
    }
   ],
   "source": [
    "car_x = car_raw[:, :-1].copy()\n",
    "car_y = car_raw[:, -1].copy()\n",
    "\n",
    "car_x_train, car_x_test, car_y_train, car_y_test = train_test_split(\n",
    "                                          car_x, car_y, test_size=0.3, random_state=5)\n",
    "\n",
    "car_y_train = car_y_train.ravel()\n",
    "car_y_test = car_y_test.ravel()\n",
    "\n",
    "#see sample division of training and testing\n",
    "print(\"Sample count of training: \", car_y_train.shape[0])\n",
    "print(\"Sample count of testing: \", car_y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc9acf",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc6127",
   "metadata": {},
   "source": [
    "We are now calculating model performance for the following model, where we are predicting everything as our majority class, and set it as a benchmark to see compare our final model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3427966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category occuring max number of times in our target variable:  unacc\n",
      "Accuracy for this model:  0.7090558766859345\n",
      "Confusion Matrix for this model: \n",
      " [[  0   0 119   0]\n",
      " [  0   0  14   0]\n",
      " [  0   0 368   0]\n",
      " [  0   0  18   0]]\n",
      "F-scores for each class for this model:  [0.         0.         0.82976325 0.        ]\n",
      "Kappa coefficient for this model is:  0.0\n",
      "MCC for this model is:  0.0\n",
      "Precision for each class for this model:  [0.         0.         0.70905588 0.        ]\n",
      "Recall for each class for this model:  [0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "cat, cat_count = np.unique(car_y_train, return_counts=True)\n",
    "max_cat = cat[cat_count == cat_count.max()][0]\n",
    "\n",
    "print(\"The category occuring max number of times in our target variable: \", max_cat)\n",
    "\n",
    "pred = np.full(car_y_test.shape, max_cat)\n",
    "\n",
    "print(\"Accuracy for this model: \", metrics.accuracy_score(car_y_test, pred))\n",
    "print(\"Confusion Matrix for this model: \\n\", metrics.confusion_matrix(car_y_test, pred))\n",
    "print(\"F-scores for each class for this model: \", metrics.f1_score(car_y_test, pred, average=None))\n",
    "print(\"Kappa coefficient for this model is: \", metrics.cohen_kappa_score(car_y_test, pred))\n",
    "print(\"MCC for this model is: \", metrics.matthews_corrcoef(car_y_test, pred))\n",
    "print(\"Precision for each class for this model: \", metrics.precision_score(car_y_test, pred, average=None))\n",
    "print(\"Recall for each class for this model: \", metrics.recall_score(car_y_test, pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab39652b",
   "metadata": {},
   "source": [
    "## Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e6313e",
   "metadata": {},
   "source": [
    "Here, we are creating a copy of our training and testing data with one-hot encoding, especially for algorithms that rely on distance calculations, eg. KNN. \n",
    "\n",
    "We also convert the categorical data into numerical by taking into account the natural ordering of the categories that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f58b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#create copies of dataset\n",
    "car_x_train_encoded = car_x_train.copy()\n",
    "car_x_test_encoded = car_x_test.copy()\n",
    "\n",
    "#fit encoder to training data\n",
    "enc = enc.fit(car_x_train_encoded)\n",
    "\n",
    "#transform datasets\n",
    "car_x_train_encoded = enc.transform(car_x_train_encoded).toarray()\n",
    "car_x_test_encoded = enc.transform(car_x_test_encoded).toarray()\n",
    "\n",
    "#ordinal encoding for numerical processing of variables\n",
    "ord_enc = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan,\n",
    "                                      categories=[['low', 'med', 'high', 'vhigh'],\n",
    "                                                 ['low', 'med', 'high', 'vhigh'],\n",
    "                                                 ['2', '3', '4', '5more'],\n",
    "                                                 ['2', '4', 'more'],\n",
    "                                                 ['small', 'med', 'big'],\n",
    "                                                 ['low', 'med', 'high']])\n",
    "\n",
    "#create copies of dataset\n",
    "car_x_train_ordinal_encoded = car_x_train.copy()\n",
    "car_x_test_ordinal_encoded = car_x_test.copy()\n",
    "\n",
    "#fit encoder to training data\n",
    "ord_enc = ord_enc.fit(car_x_train_ordinal_encoded)\n",
    "\n",
    "#transform datasets\n",
    "car_x_train_ordinal_encoded = ord_enc.transform(car_x_train_ordinal_encoded)\n",
    "car_x_test_ordinal_encoded = ord_enc.transform(car_x_test_ordinal_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f009392",
   "metadata": {},
   "source": [
    "We define a dictionary here which will record the best performance evaluation of all the models we will look at. We use MCC as our scoring method, as the data is imbalanced, it contains 70% of the 'unacc' class.\n",
    "\n",
    "Matthews Correlation Coefficient (MCC) takes all the four blocks of the Confusion Matrix into consideration in its formula. Originally developed by Matthews in 1975.\n",
    "\n",
    "Similar to Correlation Coefficient, the range of values of MCC lie between -1 to +1. As already explained, it is similar as applying Pearson Correlation Coefficient to binary classification problems where two random variables are prediction and label. That is to say, MCC is a discrete case for Pearson Correlation Coefficient.\n",
    "ref: https://sarit-maitra.medium.com/mathews-correlation-coefficient-for-imbalanced-classes-705d93184aed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c5eb0",
   "metadata": {},
   "source": [
    "To compare the model performances of all the strategies and models we try, we save the mean of MCC score in a dictionary, and check at the end the model which performs the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b54424ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc_scores = {}\n",
    "\n",
    "#adding benchmark\n",
    "mcc_scores['benchmark'] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28779d1",
   "metadata": {},
   "source": [
    "The below code is for defining the custom scorer, inner and outer cross validation folds, which will be used in evaluating all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cfb4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a custom scorer\n",
    "# we use mcc for all our model evaluations\n",
    "custom_scorer = make_scorer(matthews_corrcoef, greater_is_better=True)\n",
    "\n",
    "# code for accuracy scorer maker\n",
    "# custom_scorer = make_scorer(accuracy_score, greater_is_better=True)\n",
    "\n",
    "# create folds for cross validation\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404d028",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f61a7f",
   "metadata": {},
   "source": [
    "We start by implementing and evaluating the performance of KNN. Since all the attributes in our dataset are categorical, we use hamming distance for our distance calculations among data points. The rest of the process remains same, where er use the inner cross validation for hyperparameter tuning, and the outer cross validation for performance evaluation using our chosen scoring technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2e278",
   "metadata": {},
   "source": [
    "This code is for the one-hot encoded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5654ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ranges for hyperparameters for KNN\n",
    "p_grid_knn = {'n_neighbors' : range(1, 100), 'weights' : ['uniform', 'distance']}\n",
    "\n",
    "# classifier\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# inner CV\n",
    "clf = GridSearchCV(estimator=knn, param_grid=p_grid_knn, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['knn_one_hot'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c11212",
   "metadata": {},
   "source": [
    "The below code is for the numerical converted attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c02a16d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ranges for hyperparameters for KNN\n",
    "p_grid_knn = {'n_neighbors' : range(1, 100), 'weights' : ['uniform', 'distance']}\n",
    "\n",
    "# classifier\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# inner CV\n",
    "clf = GridSearchCV(estimator=knn, param_grid=p_grid_knn, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_ordinal_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['knn_numerical'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711ab52e",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc0a7b",
   "metadata": {},
   "source": [
    "We now move onto decision tree classifier. Similar to KNN, we use one-hot encoded dataset, and evaluate the performance of this classifier using nested cross validation and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c47b5a",
   "metadata": {},
   "source": [
    "The below code is for one hot encoded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d1f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining search space for hyperparameters for Decision tree\n",
    "p_grid_dtree = {'max_depth' : Integer(1, 15), \n",
    "          'min_samples_split': Integer(2,20), \n",
    "          'min_samples_leaf': Integer(4,10),\n",
    "          'min_impurity_decrease': Real(0,2)\n",
    "         }\n",
    "\n",
    "# classifier\n",
    "dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=dtree, search_spaces=p_grid_dtree, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['dtree_one_hot'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f1e55e",
   "metadata": {},
   "source": [
    "The below code is for our numerical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95902e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining search space for hyperparameters for Decision tree\n",
    "p_grid_dtree = {'max_depth' : Integer(1, 15), \n",
    "          'min_samples_split': Integer(2,20), \n",
    "          'min_samples_leaf': Integer(4,10),\n",
    "          'min_impurity_decrease': Real(0,2)\n",
    "         }\n",
    "\n",
    "# classifier\n",
    "dtree = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=dtree, search_spaces=p_grid_dtree, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_ordinal_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['dtree_numerical'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2ea62",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62649b",
   "metadata": {},
   "source": [
    "We now evaluate Naive Bayes classifier on our training dataset. All the process remains same as used in other algorithms. The only difference is we need are only using ordinal encoded dataset, i.e. the numerical dataset in this classifier, since we have a separate Categorical classifier.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a80a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining search space for hyperparameters for Naive Bayes\n",
    "p_grid_nb = {'alpha' : Real(0,100), \n",
    "          'fit_prior': Categorical([True,False])\n",
    "         }\n",
    "\n",
    "# classifier\n",
    "nb = naive_bayes.CategoricalNB()\n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=nb, search_spaces=p_grid_nb, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_ordinal_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['nb'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01a0769",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd42749",
   "metadata": {},
   "source": [
    "We are now evaluating logistic regression on our training dataset using the same process. We again return to our one hot encoded dataset for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0deef8",
   "metadata": {},
   "source": [
    "The below evaluation is for one-hot encoded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb62ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ranges for hyperparameters for Logistic regression\n",
    "p_grid_lreg = {\n",
    "    'penalty' : Categorical(['l1', 'l2', 'none', 'elasticnet']), \n",
    "    'tol': Real(0,1),\n",
    "    'C': Real(1,100),\n",
    "    'l1_ratio': Real(0,1)\n",
    "}\n",
    "\n",
    "#classifier\n",
    "lreg = linear_model.LogisticRegression(solver='saga') \n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=lreg, search_spaces=p_grid_lreg, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['lreg_one_hot'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18882fbb",
   "metadata": {},
   "source": [
    "The below code is for numeric converted attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c33581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ranges for hyperparameters for Logistic regression\n",
    "p_grid_lreg = {\n",
    "    'penalty' : Categorical(['l1', 'l2', 'none', 'elasticnet']), \n",
    "    'tol': Real(0,1),\n",
    "    'C': Real(1,100),\n",
    "    'l1_ratio': Real(0,1)\n",
    "}\n",
    "\n",
    "#classifier\n",
    "lreg = linear_model.LogisticRegression(solver='saga') \n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=lreg, search_spaces=p_grid_lreg, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_ordinal_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['lreg_numerical'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98aaf4",
   "metadata": {},
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b5e1c",
   "metadata": {},
   "source": [
    "We now evaluate the model performance for support vector classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4437305",
   "metadata": {},
   "source": [
    "The below code evaluates the performance for one-hot encoded, i.e, categorical handling of the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58881a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining search space\n",
    "p_grid_svc = {\n",
    "    'C': Categorical([0.0000001, 0.00001, 0.001, 0.1, 1, 10, 100, 1000]),\n",
    "    'kernel' : Categorical(['linear', 'poly', 'rbf', 'sigmoid']), \n",
    "    'gamma': Real(0.000000001,1),\n",
    "    'tol': Real(0.000000001,1)\n",
    "}\n",
    "\n",
    "# classifier\n",
    "svc = SVC() \n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=svc, search_spaces=p_grid_svc, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['svc_one_hot'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca67cf",
   "metadata": {},
   "source": [
    "We run the below code for numerical handling of our attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50d2a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining search space\n",
    "# reducing the hyperparameter search space due to complexity constraints\n",
    "p_grid_svc = {\n",
    "    'C': Categorical([0.001, 0.1, 1, 10, 100]),\n",
    "    'kernel' : Categorical(['linear', 'rbf']), \n",
    "    'gamma': Categorical(['scale', 'auto'])\n",
    "}\n",
    "\n",
    "# classifier\n",
    "svc = SVC() \n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=svc, search_spaces=p_grid_svc, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "# outer CV\n",
    "nested_score = cross_val_score(clf, X=car_x_train_ordinal_encoded, y=car_y_train, \n",
    "                               cv=outer_cv, scoring=custom_scorer, error_score='raise')\n",
    "\n",
    "mcc_scores['svc_numerical'] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d8ef1",
   "metadata": {},
   "source": [
    "## Selecting final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b579a389",
   "metadata": {},
   "source": [
    "We now compare our MCC scores on the training datasets for all the models we have built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f42334ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'benchmark': 0.0,\n",
       " 'knn_one_hot': 0.7744087597260918,\n",
       " 'knn_numerical': 0.8254232667751232,\n",
       " 'dtree_one_hot': 0.8643358805588685,\n",
       " 'dtree_numerical': 0.878822387236512,\n",
       " 'nb': 0.6859574123987107,\n",
       " 'lreg_one_hot': 0.8376353578093255,\n",
       " 'lreg_numerical': 0.61253573919297,\n",
       " 'svc_one_hot': 0.966959440927441,\n",
       " 'svc_numerical': 0.9386309882815548}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b502eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_one_hot\n"
     ]
    }
   ],
   "source": [
    "best_mcc_score = max(mcc_scores, key=mcc_scores.get)\n",
    "print(best_mcc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d534f8c",
   "metadata": {},
   "source": [
    "## Evaluate performance of selected model - Support Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71918a2",
   "metadata": {},
   "source": [
    "We now fit our selected model to the training data, and check peformance on the entire data, including test data so that we evaluate model performance on some data which has not been seen by the model before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f5c883b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for this model:  0.9965277777777778\n",
      "Confusion Matrix for this model: \n",
      " [[ 380    0    4    0]\n",
      " [   0   69    0    0]\n",
      " [   2    0 1208    0]\n",
      " [   0    0    0   65]]\n",
      "F-scores for each class for this model:  [0.9921671  1.         0.99752271 1.        ]\n",
      "Kappa coefficient for this model is:  0.9923976565306976\n",
      "MCC for this model is:  0.9924012988646376\n",
      "Precision for each class for this model:  [0.9947644  1.         0.99669967 1.        ]\n",
      "Recall for each class for this model:  [0.98958333 1.         0.99834711 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "#create copies of dataset\n",
    "car_x_train_encoded = car_x_train.copy()\n",
    "car_x_test_encoded = car_x_test.copy()\n",
    "car_x_encoded = car_x.copy()\n",
    "\n",
    "#fit encoder to training data\n",
    "enc = enc.fit(car_x_train_encoded)\n",
    "\n",
    "#transform datasets\n",
    "car_x_train_encoded = enc.transform(car_x_train_encoded).toarray()\n",
    "car_x_test_encoded = enc.transform(car_x_test_encoded).toarray()\n",
    "car_x_encoded = enc.transform(car_x_encoded).toarray()\n",
    "\n",
    "custom_scorer = make_scorer(matthews_corrcoef, greater_is_better=True)\n",
    "\n",
    "# create folds for cross validation\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=5)\n",
    "\n",
    "#search space for Bayesian hyperparameter setting\n",
    "# defining search space\n",
    "p_grid_svc = {\n",
    "    'C': Categorical([0.0000001, 0.00001, 0.001, 0.1, 1, 10, 100, 1000]),\n",
    "    'kernel' : Categorical(['linear', 'poly', 'rbf', 'sigmoid']), \n",
    "    'gamma': Real(0.000000001,1),\n",
    "    'tol': Real(0.000000001,1)\n",
    "}\n",
    "\n",
    "# classifier\n",
    "svc = SVC() \n",
    "\n",
    "# inner CV\n",
    "clf = BayesSearchCV(estimator=svc, search_spaces=p_grid_svc, \n",
    "                   cv=inner_cv, scoring=custom_scorer)\n",
    "\n",
    "clf.fit(X=car_x_train_encoded, y=car_y_train)\n",
    "clf = clf.best_estimator_\n",
    "clf.fit(X=car_x_train_encoded, y=car_y_train)\n",
    "pred = clf.predict(car_x_encoded)\n",
    "\n",
    "# evaluation metrics\n",
    "print(\"Accuracy for this model: \", metrics.accuracy_score(car_y, pred))\n",
    "print(\"Confusion Matrix for this model: \\n\", metrics.confusion_matrix(car_y, pred))\n",
    "print(\"F-scores for each class for this model: \", metrics.f1_score(car_y, pred, average=None))\n",
    "print(\"Kappa coefficient for this model is: \", metrics.cohen_kappa_score(car_y, pred))\n",
    "print(\"MCC for this model is: \", metrics.matthews_corrcoef(car_y, pred))\n",
    "print(\"Precision for each class for this model: \", metrics.precision_score(car_y, pred, average=None))\n",
    "print(\"Recall for each class for this model: \", metrics.recall_score(car_y, pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701dd9de",
   "metadata": {},
   "source": [
    "We see that the overall accuracy of our final model is around 99.6%. The precision for all classes is greater than 99%. The recall for all classes is 98%. The MCC for this model is 0.99, which means it performs much better than a random classifier. We also see the confusion matrix for all classes in our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52eab666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['acc', 'good', 'unacc', 'vgood'], dtype=object),\n",
       " array([ 384,   69, 1210,   65]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for looking at categories in confusion matrix\n",
    "np.unique(car_y, return_counts=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
